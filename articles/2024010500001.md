---
title: "G検定にむけて要素技術をまとめてみる"
emoji: "🔖"
type: "idea"
topics:
  - "読書メモ"
published: true
published_at: "2025-01-05 19:00"
---

# なにこれ
- 「[ディープラーニングG検定公式テキスト（第三版）](https://www.jdla.org/news/20240514001/)」をもとに、理解の薄い5章、6章あたりをまとめてみる。
- 技術の発展の経緯と関係性をまとめるのにクラス図を用いてみる

# クラス図にあてはめた要素技術の関連
## 画像認識
```mermaid
classDiagram
  %%Relation
  CNN <|-- LeNet
  CNN <|-- ネオコグニトロン
  CNN <|-- NeuralArchitectureSearch
  CNN <|-- R-CNN
  CNN <|-- YOLO
  R-CNN <|-- Fast R-CNN
  Fast R-CNN <|-- Faster R-CNN
  Faster R-CNN　<|-- Mask R-CNN
  FCN <|-- Mask R-CNN
  YOLO <|-- SSD
  CNN <|-- FCN
  CNN <|-- OpenPose
  FCN <|-- SegNet
  FCN <|-- DeepLab
  SegNet <|-- U-Net
  SegNet <|-- PSPNet
  DeepLab <|-- DeepLab V3plus
  PSPNet <|-- DeepLab V3plus
  LeNet <|-- AlexNet
  AlexNet <|-- VGG
  AlexNet <|-- GoogLeNet
  AlexNet <|-- ResNet
  ResNet <|-- WideResNet
  ResNet <|-- DenseNet
  ResNet <|-- SENet
  ResNet <|-- MobileNet
  NeuralArchitectureSearch <|-- NASNet
  NeuralArchitectureSearch <|-- MnasNet
  NeuralArchitectureSearch <|-- EfficientNet
  ResNet <|-- NASNet
  MobileNet <|-- MnasNet
  %%class 
  class CNN
  class ネオコグニトロン{
    単純型細胞（S細胞）
    複雑型細胞（C細胞）
  }
  class LeNet{
    畳み込み層
    プーリング層
  }  
  class AlexNet{
    全結合層
    void 物体認識()
  }
  class VGG{
    3x3フィルタ
  }
  class GoogLeNet{
    Inceptionモジュール
  }
  class ResNet{
    スキップ結合
  }
  class WideResNet{
    +フィルタ数
  }
  class DenseNet{
    +enhance:スキップ結合
  }
  class SENet{
    Attention
  }
  class MobileNet{
    DeepWise Separable Convolution
  }
  class NeuralArchitectureSearch{
    深層強化学習
  }
  class NASNet{
    Residual Block
  }
  class MnasNet{
    モバイル端末向け計算量最適化
  }
  class EfficientNet{
    Compound Scaling Method
  }
  class R-CNN{
    selective search
    SVM
    void 2段階物体検出()
  }
  class Fast R-CNN{
    簡略・高速化
  }
  class Faster R-CNN{
    ReginalProposalNetwork（FPN）
  }
  class YOLO{
    出力層のグリッド化
    void 1段階物体検出()
  }
  class SSD{
    デフォルトボックス
  }
  class FCN{
    void セマンティックセグメンテーション()
  }
  class SegNet{
    エンコーダ
    デコーダ
    畳み込み層とプーリング層の積層化
  }
  class U-Net{
    デコーダでのエンコーダ入力サイズ出力調整
  }
  class PSPNet{
    Pyramid Pooling Module
  }
  class DeepLab{
    Atrous convolution
  }
  class DeepLab V3plus{
    Atrous Spatial Pooling Pyramid
  }
  class OpenPose{
    信頼度マップ
    Parts Affinity Firelds
    Convolutional Pose Machine
    void 姿勢推定()
  }
  class Mask R-CNN{
    マルチタスク
  }



```

## 音声認識
```mermaid
classDiagram
  %%Relation
  A-D変換 -- 高速フーリエ変換
  高速フーリエ変換 -- 音響モデル
  高速フーリエ変換 -- 言語モデル  
  音響モデル　<|-- 隠れマルコフモデル
  音響モデル　<|-- RNN
  言語モデル <|-- n-gram言語モデル


  %%class
  class A-D変換{
    void パルス符号変調()
  }
  class 高速フーリエ変換{
    音色（スペクトラム包絡：メル周波数ケプストラム係数）
    音韻（フォルマント周波数）
    void 周波数スペクトル変換()
  }
  class 音響モデル
  class 隠れマルコフモデル{
    void 音素列変換()
  }
  class RNN{
    Connectionist Temporal Classification
  }
  class 言語モデル
  class n-gram言語モデル{
    条件付確率（N-1）
  }


```

## 自然言語処理

解析、学習、推論の観点が混線しそう


```mermaid
classDiagram
  %%relation
  n-gram <|-- Bag-of-n-grams
  Bag-of-Words <|-- Bag-of-n-grams
  Bag-of-Words -- one-hot vector
  one-hot vector -- word2vec
  word2vec <|-- fastText
  TF-IDF <|-- ELMo
  word2vec <|-- ELMo
  RNN <|-- Transformer
  Transformer <|-- GPT
  Transformer <|-- BERT
  GPT <|-- ChatGPT
  BERT <|-- Bard

  %%class
  class n-gram{
    単語を並べた文字列単位
  }
  class Bag-of-Words{
    単語の集合としての文章
  }
  class Bag-of-n-grams{
    出現順序の考慮
  }
  class TF-IDF{
    TF(文章内での単語の出現割合)
    IDF(単語が出現する文章の割合)
  }
  class one-hot vector{
    void ベクトル変換()
  }
  class word2vec{
    分散表現
    void スキップグラム()
    void CBOW()
    void 次元圧縮()
    void 主成分分析()
  }
  class fastText{
    単語の部分文字列の考慮
  }
  class ELMo{
    文脈を考慮した分散表現
  }
  class RNN
  class Transformer{
    Source-Target Attention
    Self Attention
  }
  class GPT{
    事前学習モデル
    void 自然言語推論()
    void 質問応答()
    void 意味的類似度()
    void 文書分類()
  }
  class BERT{
    事前学習モデル
    Masked Language Model
    Next Sentence Prediction
    void 自然言語推論()
    void 質問応答()
    void 意味的類似度()
    void 文書分類()
  }
  class ChatGPT{
    大規模言語モデル
    Reinforcement Learning from Human Feedback
  }
  class Bard{
    大規模言語モデル
  }
```

## データ生成

```mermaid
classDiagram
  %%relation
  DNN <|-- GAN
  DNN <|-- VAE
  DNN <|-- Diffusion Model
  %%class
  class DNN
  class GAN{
    generator
    discriminator
  }
  class VAE{
    encoder
    decoder
  }
  class Diffusion Model{
    拡散過程
    逆拡散過程
  }
```

# この先
この辺を源流として、発展モデル、マルチモーダルモデルを組み合わせで理解していけるといいな

# 参考
ちゃんと理解するにはこの資料を読み込みたい
[深層学習による自然言語処理入門: word2vecからBERT, GPT-3まで](https://www.docswell.com/s/ydnjp/K3YMDZ-2021-07-21-152903)