---
title: "Garakってなに"
emoji: "🦆"
type: "idea"
topics:
  - "Garak"
published: true
published_at: "2025-01-10 21:00"
---


# なぜ作成したのか
しらないセキュリティ用語を勉強しようという試み

# 参考
- [LLMの脆弱性を無料で診断できるツールGarakが登場　多岐にわたる機能を提供](https://www.itmedia.co.jp/enterprise/articles/2501/09/news065.html)（ITmedia会員限定記事）
- [Welcome to garak!](https://docs.garak.ai/garak)
- [Garak - Open Source LLM Vulnerability Scanner for AI Red-Teaming](https://gbhackers.com/garak/)
- [NVIDIA/garak: the LLM vulnerability scanner](https://github.com/NVIDIA/garak)


# Garak is 何

Garakは、大規模言語モデル（LLM）の脆弱性を検出するために設計されたオープンソースのツールです。

# 登場の背景となる技術トレンド

- 近年、ChatGPTやBERTなどの大規模言語モデル（LLM）の活用が急速に広がっています。
- これらのモデルは自然言語処理の分野で高い性能を示し、多様なアプリケーションに組み込まれています。
- しかし、その高度な生成能力ゆえに、プロンプトインジェクションやジェイルブレイクといった新たな攻撃手法が登場し、LLM自体のセキュリティリスクが懸念されています。
- このような背景から、LLMの脆弱性を検出し、対策を講じる必要性が高まっています。

# シーンの抱える課題

LLMの普及に伴い、以下のようなセキュリティ上の課題が浮上しています。これらの脆弱性は、ユーザーの信頼を損ない、法的な問題を引き起こす可能性があります。


## プロンプトインジェクション
- 悪意のある入力により、モデルが意図しない応答を生成するリスク。

## データ漏洩
- モデルが訓練データや機密情報を不適切に出力する可能性。

## 有害なコンテンツ生成
- モデルが不適切または有害な情報を生成するリスク。


# 解決策としてのGarak、その概要

Garakは、LLMの脆弱性を検出・評価するためのツールとして開発されました。ネットワークセキュリティスキャナーのLLM版とも言える存在で、モデルに対して擬似的な攻撃を行い、その脆弱性を評価します。

## 開発元
- NVIDIA社が提供するオープンソースツールです。 

## 利用技術・特性
- GarakはPythonで実装されており、コマンドラインから操作可能です。
- 多様なプラグインと数千のプロンプトを使用して、LLMのセキュリティをテストします。 

- 対応プラットフォーム:
  - Hugging Face
  - OpenAI、
  - Replicate、
  - Cohere、
  - NVIDIA NIM、
  - OctoAI、
  - Groq など
- APIベースのモデルやローカルモデルでのテストも可能。また
- RESTエンドポイントとの統合やカスタムプラグインの開発をサポートしており、ユーザーが独自のニーズに合わせた脆弱性診断を実行できる柔軟性を持つ。
- LLMを対象としたプローブ（テスト）にはプロンプトインジェクションの検出や誤情報生成の評価、ポイズニングのテストなどAIの安全性や倫理性に直結する多岐にわたる項目が含まれる。
- デバッグやランタイム用のプライマリーログ（garak.log）、プローブの詳細を含む構造化形式のJSONレポートといったログが生成され、ログからデータを分析できる。


# Garakがいかにして課題解決に寄与するか

- Garakは、以下の方法でLLMのセキュリティ課題の解決に寄与します。

  - **脆弱性の可視化**: 
    - モデルの弱点を明確にリスト化し、どの部分が危険であるかを把握できます。

  - **セキュリティ対策の強化**: 
    - 検出された脆弱性に基づき、適切な対策を講じることが可能です。

  - **オープンソースの利便性**: 
    - 誰でも利用できるため、広く普及しやすく、コミュニティによる継続的な改善が期待できます。

# 類似製品との比較、優位性

- LLMの脆弱性スキャナーとしては、Garakの他にも以下のツールがあります。

  - **[Giskard](https://www.giskard.ai/)**: 
    - LLMのリスク検査手法を提供するツール。 
    - 参考記事
      -  [【セキュリティ】富士通が発表したLLM安全性評価ツール比較、GarakとGiskardの性能を徹底検証！](https://summary-gpt.net/2024/11/02/security/143/)
      -  ※記事の情報源は [ＡＩＤＢの会員限定記事](https://ai-data-base.com/archives/77301) のため、1次情報は未確認

- Garakの優位性は、その多様なプラグインと豊富なプロンプトにより、LLMの多面的な脆弱性を検出できる点にあります。
- また、NVIDIA社のサポートにより、信頼性と継続的なアップデートが期待できます。

# Garakの将来性

- LLMの利用がさらに拡大し、攻撃手法も高度化する中、Garakの重要性は増すと考えられます。
- オープンソースであるため、コミュニティによる機能拡張や新たな脆弱性への対応が進むことが期待されます。
- また、NVIDIA社の継続的なサポートにより、最新の技術トレンドや脅威に対応した機能強化が図られるでしょう。

# 実際に使ってみるには

- やはり「LLMの脆弱性を無料で診断できるツール」というが魅力的。

- Garakはプログラミング言語「Python」のサードパーティーソフトウェアリポジトリである「Python Package Index」（以下、PyPI）から最新リリースをインストールでき、無償で利用できる。

- Garakの詳細、ソースコードについては、[公式GitHubリポジトリ](https://github.com/NVIDIA/garak) で確認できます。

- Garakのインストール方法や基本的な使い方などは公式ドキュメントサイト「[Welcome to garak!](https://docs.garak.ai/garak)」で解説されています。

休みあけたら使っても大丈夫そうかセキュリティチェックしておこうかな